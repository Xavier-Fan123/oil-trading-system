# Logstash Pipeline Configuration for Oil Trading System

# Input plugins
input {
  # Beats input for structured logs
  beats {
    port => 5044
    type => "beats"
  }
  
  # File input for application logs
  file {
    path => ["/usr/share/logstash/logs/oil-trading-*.txt"]
    type => "application"
    codec => "json"
    start_position => "beginning"
    sincedb_path => "/usr/share/logstash/sincedb_oil_trading"
    discover_interval => 15
    stat_interval => 1
    tags => ["oil-trading", "application"]
  }
  
  # Syslog input for system logs
  syslog {
    port => 5000
    type => "syslog"
  }
  
  # TCP input for custom application logs
  tcp {
    port => 5001
    codec => json_lines
    type => "tcp"
  }
  
  # HTTP input for webhook logs
  http {
    port => 8080
    codec => "json"
    type => "webhook"
  }
}

# Filter plugins
filter {
  # Parse timestamp for all logs
  if [type] == "application" {
    # Handle Serilog JSON format
    if [Timestamp] {
      date {
        match => [ "Timestamp", "yyyy-MM-dd'T'HH:mm:ss.SSSSSSS'Z'", "yyyy-MM-dd'T'HH:mm:ss.SSS'Z'" ]
        target => "@timestamp"
      }
    }
    
    # Extract log level
    if [Level] {
      mutate {
        rename => { "Level" => "log_level" }
        lowercase => [ "log_level" ]
      }
    }
    
    # Extract exception details
    if [Exception] {
      mutate {
        rename => { "Exception" => "exception_details" }
      }
      
      # Parse exception stack trace
      if [exception_details] {
        grok {
          match => { "exception_details" => "(?<exception_type>[^:]+):\s*(?<exception_message>.*?)(\s+at\s+(?<stack_trace>.*))?$" }
          tag_on_failure => ["_grokparsefailure_exception"]
        }
      }
    }
    
    # Extract request details
    if [RequestPath] {
      mutate {
        rename => { "RequestPath" => "request_path" }
      }
      
      # Parse API endpoints
      grok {
        match => { "request_path" => "^/api/(?<api_controller>[^/]+)/?(?<api_action>[^/?]*)?" }
        tag_on_failure => ["_grokparsefailure_api"]
      }
    }
    
    # Extract performance metrics
    if [ElapsedMilliseconds] {
      mutate {
        convert => { "ElapsedMilliseconds" => "float" }
        rename => { "ElapsedMilliseconds" => "response_time_ms" }
      }
      
      # Categorize response times
      if [response_time_ms] {
        if [response_time_ms] <= 100 {
          mutate { add_field => { "response_category" => "fast" } }
        } else if [response_time_ms] <= 500 {
          mutate { add_field => { "response_category" => "normal" } }
        } else if [response_time_ms] <= 2000 {
          mutate { add_field => { "response_category" => "slow" } }
        } else {
          mutate { add_field => { "response_category" => "very_slow" } }
        }
      }
    }
    
    # Extract business context
    if [Properties] {
      # Extract contract information
      if [Properties][ContractId] {
        mutate {
          add_field => { "business_contract_id" => "%{[Properties][ContractId]}" }
        }
      }
      
      if [Properties][TradingPartnerId] {
        mutate {
          add_field => { "business_partner_id" => "%{[Properties][TradingPartnerId]}" }
        }
      }
      
      if [Properties][ProductType] {
        mutate {
          add_field => { "business_product_type" => "%{[Properties][ProductType]}" }
        }
      }
      
      if [Properties][UserId] {
        mutate {
          add_field => { "business_user_id" => "%{[Properties][UserId]}" }
        }
      }
      
      # Extract risk information
      if [Properties][RiskMetric] {
        mutate {
          add_field => { "risk_metric_type" => "%{[Properties][RiskMetric]}" }
        }
      }
      
      if [Properties][VaRValue] {
        mutate {
          convert => { "[Properties][VaRValue]" => "float" }
          add_field => { "risk_var_value" => "%{[Properties][VaRValue]}" }
        }
      }
    }
  }
  
  # Parse system logs
  if [type] == "syslog" {
    grok {
      match => { "message" => "%{SYSLOGTIMESTAMP:syslog_timestamp} %{IPORHOST:syslog_server} %{DATA:syslog_program}(?:\[%{POSINT:syslog_pid}\])?: %{GREEDYDATA:syslog_message}" }
    }
    
    if [syslog_timestamp] {
      date {
        match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
        target => "@timestamp"
      }
    }
  }
  
  # Parse beats logs
  if [type] == "beats" {
    # Handle Filebeat logs
    if [fields][log_type] {
      mutate {
        add_field => { "log_source" => "%{[fields][log_type]}" }
      }
    }
  }
  
  # Add common fields
  mutate {
    add_field => { 
      "environment" => "${ENVIRONMENT:development}"
      "service_name" => "oil-trading-api"
      "service_version" => "1.0.0"
      "parsed_at" => "%{+yyyy-MM-dd'T'HH:mm:ss.SSS'Z'}"
    }
  }
  
  # GeoIP enrichment for external IPs
  if [client_ip] and [client_ip] !~ /^(10\.|192\.168\.|172\.(1[6-9]|2[0-9]|3[0-1])\.|127\.|169\.254\.)/ {
    geoip {
      source => "client_ip"
      target => "geoip"
      database => "/usr/share/logstash/geoip/GeoLite2-City.mmdb"
    }
  }
  
  # Remove unnecessary fields
  mutate {
    remove_field => [ "host", "agent", "ecs", "log", "input", "@version" ]
  }
  
  # Handle parsing failures
  if "_grokparsefailure" in [tags] {
    mutate {
      add_field => { "parse_error" => "true" }
      add_tag => [ "parse_failure" ]
    }
  }
}

# Output plugins
output {
  # Output to Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    
    # Dynamic index naming based on log type and date
    index => "oil-trading-%{type}-%{+YYYY.MM.dd}"
    
    # Use document type based on log level for application logs
    if [type] == "application" {
      if [log_level] == "error" or [log_level] == "fatal" {
        index => "oil-trading-errors-%{+YYYY.MM.dd}"
      } else if [log_level] == "warning" {
        index => "oil-trading-warnings-%{+YYYY.MM.dd}"
      } else if [api_controller] {
        index => "oil-trading-api-%{+YYYY.MM.dd}"
      }
    }
    
    # Performance index for slow requests
    if [response_time_ms] and [response_time_ms] > 1000 {
      index => "oil-trading-performance-%{+YYYY.MM.dd}"
    }
    
    # Business events index
    if [business_contract_id] or [business_partner_id] {
      index => "oil-trading-business-%{+YYYY.MM.dd}"
    }
    
    # Risk events index
    if [risk_metric_type] or [risk_var_value] {
      index => "oil-trading-risk-%{+YYYY.MM.dd}"
    }
    
    # Template management
    manage_template => true
    template_name => "oil-trading"
    template_pattern => "oil-trading-*"
    template => "/usr/share/logstash/templates/oil-trading-template.json"
  }
  
  # Debug output (remove in production)
  if [environment] == "development" {
    stdout {
      codec => rubydebug {
        metadata => true
      }
    }
  }
  
  # Dead letter queue for failed events
  if "_elasticsearch_output_failure" in [tags] {
    file {
      path => "/usr/share/logstash/dead_letter_queue/failed_events_%{+YYYY_MM_dd}.log"
      codec => json_lines
    }
  }
}