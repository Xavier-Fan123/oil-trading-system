#!/bin/bash

# ğŸ”„ çŸ³æ²¹äº¤æ˜“ç³»ç»Ÿç”Ÿäº§æ•°æ®å¤‡ä»½è„šæœ¬
# è‡ªåŠ¨å¤‡ä»½PostgreSQLæ•°æ®åº“å’Œé‡è¦é…ç½®æ–‡ä»¶

set -e

# é…ç½®å˜é‡
BACKUP_DIR="/app/backups"
DATE=$(date +%Y%m%d_%H%M%S)
RETENTION_DAYS=30

# ä»ç¯å¢ƒå˜é‡è·å–æ•°æ®åº“é…ç½®
DB_HOST=${DB_HOST:-localhost}
DB_NAME=${DB_NAME:-oiltrading_prod}
DB_USER=${DB_USER:-oil_trading_admin}
DB_PASSWORD=${DB_PASSWORD}

# æ—¥å¿—å‡½æ•°
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1"
}

# åˆ›å»ºå¤‡ä»½ç›®å½•
create_backup_directory() {
    mkdir -p "${BACKUP_DIR}/database"
    mkdir -p "${BACKUP_DIR}/config"
    mkdir -p "${BACKUP_DIR}/logs"
}

# æ•°æ®åº“å¤‡ä»½
backup_database() {
    log "å¼€å§‹æ•°æ®åº“å¤‡ä»½..."
    
    local backup_file="${BACKUP_DIR}/database/oiltrading_backup_${DATE}.sql"
    
    # ä½¿ç”¨pg_dumpè¿›è¡Œå¤‡ä»½
    PGPASSWORD="${DB_PASSWORD}" pg_dump \
        -h "${DB_HOST}" \
        -U "${DB_USER}" \
        -d "${DB_NAME}" \
        --verbose \
        --clean \
        --create \
        --if-exists \
        --format=custom \
        --file="${backup_file}.custom"
    
    # åŒæ—¶åˆ›å»ºSQLæ ¼å¼å¤‡ä»½ï¼ˆä¾¿äºäººå·¥æŸ¥çœ‹ï¼‰
    PGPASSWORD="${DB_PASSWORD}" pg_dump \
        -h "${DB_HOST}" \
        -U "${DB_USER}" \
        -d "${DB_NAME}" \
        --verbose \
        --clean \
        --create \
        --if-exists \
        > "${backup_file}"
    
    # å‹ç¼©å¤‡ä»½æ–‡ä»¶
    gzip "${backup_file}"
    
    log "æ•°æ®åº“å¤‡ä»½å®Œæˆ: ${backup_file}.gz"
    log "è‡ªå®šä¹‰æ ¼å¼å¤‡ä»½: ${backup_file}.custom"
}

# é…ç½®æ–‡ä»¶å¤‡ä»½
backup_configs() {
    log "å¼€å§‹é…ç½®æ–‡ä»¶å¤‡ä»½..."
    
    local config_backup_dir="${BACKUP_DIR}/config/config_${DATE}"
    mkdir -p "${config_backup_dir}"
    
    # å¤‡ä»½é‡è¦é…ç½®æ–‡ä»¶
    [ -f ".env" ] && cp ".env" "${config_backup_dir}/"
    [ -f "appsettings.Production.json" ] && cp "appsettings.Production.json" "${config_backup_dir}/"
    [ -f "docker-compose.production.yml" ] && cp "docker-compose.production.yml" "${config_backup_dir}/"
    
    # å¤‡ä»½Nginxé…ç½®
    if [ -d "nginx" ]; then
        cp -r "nginx" "${config_backup_dir}/"
    fi
    
    # å¤‡ä»½ç›‘æ§é…ç½®
    if [ -d "monitoring" ]; then
        cp -r "monitoring" "${config_backup_dir}/"
    fi
    
    # æ‰“åŒ…é…ç½®æ–‡ä»¶
    tar -czf "${config_backup_dir}.tar.gz" -C "${BACKUP_DIR}/config" "config_${DATE}"
    rm -rf "${config_backup_dir}"
    
    log "é…ç½®æ–‡ä»¶å¤‡ä»½å®Œæˆ: ${config_backup_dir}.tar.gz"
}

# åº”ç”¨æ—¥å¿—å¤‡ä»½
backup_logs() {
    log "å¼€å§‹æ—¥å¿—æ–‡ä»¶å¤‡ä»½..."
    
    local log_backup_dir="${BACKUP_DIR}/logs/logs_${DATE}"
    mkdir -p "${log_backup_dir}"
    
    # å¤‡ä»½åº”ç”¨æ—¥å¿—
    if [ -d "logs" ]; then
        cp -r logs/* "${log_backup_dir}/" 2>/dev/null || true
    fi
    
    # å¦‚æœæœ‰æ—¥å¿—æ–‡ä»¶ï¼Œåˆ™æ‰“åŒ…
    if [ "$(ls -A ${log_backup_dir})" ]; then
        tar -czf "${log_backup_dir}.tar.gz" -C "${BACKUP_DIR}/logs" "logs_${DATE}"
        rm -rf "${log_backup_dir}"
        log "æ—¥å¿—å¤‡ä»½å®Œæˆ: ${log_backup_dir}.tar.gz"
    else
        rm -rf "${log_backup_dir}"
        log "æ²¡æœ‰æ‰¾åˆ°æ—¥å¿—æ–‡ä»¶ï¼Œè·³è¿‡æ—¥å¿—å¤‡ä»½"
    fi
}

# æ¸…ç†æ—§å¤‡ä»½
cleanup_old_backups() {
    log "æ¸…ç†${RETENTION_DAYS}å¤©å‰çš„å¤‡ä»½..."
    
    # æ¸…ç†æ•°æ®åº“å¤‡ä»½
    find "${BACKUP_DIR}/database" -name "*.sql.gz" -mtime +${RETENTION_DAYS} -delete 2>/dev/null || true
    find "${BACKUP_DIR}/database" -name "*.custom" -mtime +${RETENTION_DAYS} -delete 2>/dev/null || true
    
    # æ¸…ç†é…ç½®æ–‡ä»¶å¤‡ä»½
    find "${BACKUP_DIR}/config" -name "*.tar.gz" -mtime +${RETENTION_DAYS} -delete 2>/dev/null || true
    
    # æ¸…ç†æ—¥å¿—å¤‡ä»½
    find "${BACKUP_DIR}/logs" -name "*.tar.gz" -mtime +${RETENTION_DAYS} -delete 2>/dev/null || true
    
    log "æ—§å¤‡ä»½æ¸…ç†å®Œæˆ"
}

# å¤‡ä»½éªŒè¯
verify_backup() {
    log "éªŒè¯å¤‡ä»½æ–‡ä»¶å®Œæ•´æ€§..."
    
    local backup_file="${BACKUP_DIR}/database/oiltrading_backup_${DATE}.sql.gz"
    local custom_backup="${BACKUP_DIR}/database/oiltrading_backup_${DATE}.sql.custom"
    
    # æ£€æŸ¥å¤‡ä»½æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¤§å°å¤§äº0
    if [ -f "${backup_file}" ] && [ -s "${backup_file}" ]; then
        log "âœ“ SQLå¤‡ä»½æ–‡ä»¶éªŒè¯æˆåŠŸ"
    else
        log "âœ— SQLå¤‡ä»½æ–‡ä»¶éªŒè¯å¤±è´¥"
        return 1
    fi
    
    if [ -f "${custom_backup}" ] && [ -s "${custom_backup}" ]; then
        log "âœ“ è‡ªå®šä¹‰æ ¼å¼å¤‡ä»½æ–‡ä»¶éªŒè¯æˆåŠŸ"
    else
        log "âœ— è‡ªå®šä¹‰æ ¼å¼å¤‡ä»½æ–‡ä»¶éªŒè¯å¤±è´¥"
        return 1
    fi
    
    # å°è¯•è§£å‹ç¼©æµ‹è¯•
    if gzip -t "${backup_file}" 2>/dev/null; then
        log "âœ“ å¤‡ä»½æ–‡ä»¶å‹ç¼©å®Œæ•´æ€§éªŒè¯æˆåŠŸ"
    else
        log "âœ— å¤‡ä»½æ–‡ä»¶å‹ç¼©å®Œæ•´æ€§éªŒè¯å¤±è´¥"
        return 1
    fi
}

# å‘é€å¤‡ä»½æŠ¥å‘Šï¼ˆå¯é€‰ï¼‰
send_backup_report() {
    local status=$1
    local backup_size=$(du -sh "${BACKUP_DIR}/database/oiltrading_backup_${DATE}.sql.gz" 2>/dev/null | cut -f1)
    
    log "å¤‡ä»½æŠ¥å‘Š:"
    log "- å¤‡ä»½æ—¶é—´: ${DATE}"
    log "- å¤‡ä»½çŠ¶æ€: ${status}"
    log "- å¤‡ä»½å¤§å°: ${backup_size:-æœªçŸ¥}"
    log "- å¤‡ä»½ä½ç½®: ${BACKUP_DIR}"
    
    # è¿™é‡Œå¯ä»¥æ·»åŠ é‚®ä»¶æˆ–Slacké€šçŸ¥é€»è¾‘
    # ä¾‹å¦‚: curl -X POST -H 'Content-type: application/json' --data "{\"text\":\"Backup ${status}: ${backup_size}\"}" YOUR_SLACK_WEBHOOK_URL
}

# ä¸»å‡½æ•°
main() {
    log "å¼€å§‹æ‰§è¡Œç”Ÿäº§ç¯å¢ƒå¤‡ä»½..."
    
    create_backup_directory
    
    # æ‰§è¡Œå¤‡ä»½
    backup_database
    backup_configs
    backup_logs
    
    # éªŒè¯å¤‡ä»½
    if verify_backup; then
        log "å¤‡ä»½éªŒè¯æˆåŠŸ"
        cleanup_old_backups
        send_backup_report "æˆåŠŸ"
        log "âœ… å¤‡ä»½ä»»åŠ¡å®Œæˆ"
    else
        log "å¤‡ä»½éªŒè¯å¤±è´¥"
        send_backup_report "å¤±è´¥"
        log "âŒ å¤‡ä»½ä»»åŠ¡å¤±è´¥"
        exit 1
    fi
}

# é”™è¯¯å¤„ç†
trap 'log "å¤‡ä»½è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯"; send_backup_report "é”™è¯¯"; exit 1' ERR

# æ‰§è¡Œä¸»å‡½æ•°
main "$@"